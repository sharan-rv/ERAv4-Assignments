{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Why PyTorch?\n",
        "\n",
        "Super cool library with great research based applications - some of them are greatly optimized and runs C/C++ code under the hood.  \n",
        "\n",
        "âœ… **In short**: PyTorch is the framework of choice for researchers and practitioners who want rapid prototyping, strong community support, and smooth paths to productionâ€”while TensorFlow retains strengths in debugging, visualization, and some enterprise-scale workflows.\n",
        "---\n",
        "\n",
        "## PyTorch vs TensorFlow\n",
        "\n",
        "| **PyTorch**                                   | **TensorFlow**                                                            |\n",
        "| --------------------------------------------- | ------------------------------------------------------------------------- |\n",
        "| Dynamic computation graphs (eager by default) | Static graphs by default (dynamic support improved via Keras integration) |\n",
        "| Explicit CPU/GPU control                      | Simplified since TF 2.0 but less direct                                   |\n",
        "| Pythonic, intuitive, faster to prototype      | Steeper learning curve                                                    |\n",
        "| Strong documentation                          | Industry-leading documentation                                            |\n",
        "| Uses external tools for visualization/logging | Built-in **TensorBoard**                                                  |\n",
        "| Lightweight, easy experimentation             | Heavier deployment dependencies                                           |\n",
        "| Debugging can be harder                       | Strong debugging tools                                                    |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "W5Ex8zCBnqfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scientific Computing with PyTorch\n",
        "\n",
        "The **scientific computing power** of PyTorch is built on its **Tensor library** and rich ecosystem of tensor operations.\n",
        "\n",
        "![tensor](https://thepracticaldev.s3.amazonaws.com/i/bp6ux6ppf5t5amwkxklq.jpg)\n",
        "\n",
        "At its core, a **tensor** is an *n-dimensional array*â€”similar to a NumPy array but with additional deep learning and GPU acceleration capabilities.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# NumPy\n",
        "\n",
        "![Numpy Ops](https://www.researchgate.net/publication/371375140/figure/fig2/AS:11431281194962536@1696298785617/Array-Slicing-in-NumPy-illustration-inspired-by.png)\n",
        "\n",
        "\n",
        "\n",
        "* **NumPy** is the de facto library for scientific computing in Python, widely used for linear algebra, statistical operations, and nD arrays.\n",
        "* **PyTorch Tensors** mirror NumPyâ€™s API closely, making it easy for NumPy users to adopt PyTorch.\n",
        "* Unlike NumPy, PyTorch tensors come with **native GPU support**, enabling large-scale computations to run orders of magnitude faster.\n",
        "* PyTorch and NumPy are **highly interoperable**:\n",
        "\n",
        "  * Convert a NumPy array â†’ PyTorch tensor: `torch.from_numpy(ndarray)`\n",
        "  * Convert a PyTorch tensor â†’ NumPy array: `tensor.numpy()`\n",
        "\n",
        "---\n",
        "\n",
        "## Advantages of PyTorch Tensors\n",
        "\n",
        "1. **GPU Acceleration**\n",
        "\n",
        "   * Run tensor operations on CUDA-enabled GPUs with a simple `.to('cuda')` or `.cuda()` call.\n",
        "   * Easily switch between CPU and GPU execution without code rewrites.\n",
        "\n",
        "2. **Autograd Support**\n",
        "\n",
        "   * PyTorch tensors integrate with the **autograd engine**, automatically tracking gradients for optimization.\n",
        "   * This makes tensors not just numerical arrays but also core building blocks for training neural networks.\n",
        "\n",
        "3. **Rich Mathematical Operations**\n",
        "\n",
        "   * Built-in support for advanced linear algebra, convolution, Fourier transforms, and statistical functions.\n",
        "   * Optimized under the hood with low-level libraries like **MKL**, **cuBLAS**, and **cuDNN**.\n",
        "\n",
        "4. **Seamless Integration**\n",
        "\n",
        "   * Interoperable with libraries like SciPy, Pandas, and scikit-learn.\n",
        "   * Exportable to **ONNX** for use across other frameworks and runtimes.\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Example\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# NumPy array\n",
        "np_array = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "torch_tensor = torch.from_numpy(np_array)\n",
        "\n",
        "# Move tensor to GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch_tensor = torch_tensor.to('cuda')\n",
        "\n",
        "print(torch_tensor)\n",
        "```\n",
        "\n",
        "âœ… With just a few lines, the same scientific computing workflow can scale from CPU â†’ GPU seamlessly.\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ‘‰ **In short:**\n",
        "\n",
        "* **NumPy** = the gold standard for CPU-based scientific computing.\n",
        "* **PyTorch tensors** = NumPy + GPU acceleration + automatic differentiation â†’ making them the foundation for modern deep learning.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YWDMSWeTpIQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Philosophy\n",
        "\n",
        "PyTorch was designed with a clear philosophy that prioritizes **developer experience**:\n",
        "\n",
        "* **Stay out of the way** â€“ Lightweight and minimal abstractions, so you focus on solving problems, not fighting the framework.\n",
        "* **Cater to the impatient** â€“ Quick to prototype, intuitive to learn, and fast to execute.\n",
        "* **Promote linear code flow** â€“ No hidden sessions or compilation steps; what you write is what runs.\n",
        "* **Full Python interoperability** â€“ Seamlessly integrates with the Python ecosystem (NumPy, SciPy, Pandas, scikit-learn, etc.).\n",
        "* **As fast as anything else** â€“ Competitive performance with other deep learning frameworks.\n",
        "\n",
        "---\n",
        "\n",
        "## Debugging in PyTorch\n",
        "\n",
        "Because **PyTorch is a Python extension**, debugging is simple and familiar:\n",
        "\n",
        "* Any **Python debugger** (e.g., `pdb`, `ipdb`, or IDE debuggers) works out of the box.\n",
        "* Even the humble `print()` function works directly on tensors, autograd objects, and models.\n",
        "* Errors are raised at runtime (thanks to dynamic graphs), making it much easier to trace issues back to source code.\n",
        "\n",
        "This makes PyTorch particularly appealing for researchers and developers who iterate quickly and need **transparent debugging**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why PyTorch Got So Popular\n",
        "\n",
        "To train deep neural networks, frameworks rely on **computational graphs**â€”structures that represent operations and their derivatives for backpropagation.\n",
        "\n",
        "![cgs](https://pytorch.org/assets/images/augmented_computational_graph.png)\n",
        "\n",
        "Traditionally, frameworks like TensorFlow used **static computation graphs** (define-then-run). These graphs are fixed before execution, which allows optimizations but makes experimentation cumbersome.\n",
        "\n",
        "PyTorch introduced **Dynamic Computation Graphs** (define-by-run):\n",
        "\n",
        "* Graphs are built **on the fly** as operations occur.\n",
        "* Debugging is intuitive, since errors appear exactly where they happen.\n",
        "* Flexible for advanced models, research experiments, and quick iteration.\n",
        "\n",
        "---\n",
        "\n",
        "## PyTorch vs TensorFlow: The Modern Debate\n",
        "\n",
        "Over the years, the gap between PyTorch and TensorFlow has narrowed (especially after TensorFlow 2.0 introduced eager execution). Yet, PyTorch remains the framework of choice for many researchers and developers due to several advantages:\n",
        "\n",
        "1. **Ease of Learning & Use**\n",
        "\n",
        "   * Pythonic syntax, intuitive APIs, and define-by-run graphs make PyTorch friendly for beginners and researchers alike.\n",
        "\n",
        "2. **Research Flexibility**\n",
        "\n",
        "   * Dynamic graphs let you modify architectures on the fly, perfect for prototyping and experimental work.\n",
        "\n",
        "3. **Deep Python Integration**\n",
        "\n",
        "   * Designed from the ground up to blend with Python tools and workflows, making it feel â€œnativeâ€ in scientific computing pipelines.\n",
        "\n",
        "4. **Community & Ecosystem**\n",
        "\n",
        "   * Hugely popular in academia and research. The community contributes rich tutorials, papers, and open-source libraries across CV, NLP, RL, and more.\n",
        "\n",
        "5. **Dynamic vs Static Graphs**\n",
        "\n",
        "   * While TensorFlow supports dynamic graphs now, PyTorch was inherently designed for themâ€”so its implementation is often smoother and more intuitive.\n",
        "\n",
        "6. **Model Deployment**\n",
        "\n",
        "   * TensorFlow still leads in enterprise deployment (TensorFlow Serving, TF Lite).\n",
        "   * But PyTorch has **TorchScript**, **TorchServe**, and **PyTorch Mobile**, significantly closing the gap.\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ‘‰ **In short:**\n",
        "PyTorch rose to dominance because it **put researchers first**â€”prioritizing flexibility, ease of use, and Python integration. With deployment tools now mature, PyTorch today is not just for prototyping but also for **production at scale**.\n",
        "\n"
      ],
      "metadata": {
        "id": "HC9h05pKtFpq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlZjLvKRhXq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24cd571-12ce-43f8-9301-ee770b72a2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch #its preinstalled on Colab"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bBfjUUTvc77",
        "outputId": "8ef9435b-780f-4e80-e3c8-c07496c89c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "V0 = np.array(1.3)\n",
        "V1 = np.array([1., 2., 3.])\n",
        "V2 = np.array([[1., 2.], [4., 5.]])\n",
        "print(f'{V0}, {V1}, {V2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2g_ss7Avnuy",
        "outputId": "41b5921e-f716-458a-b33d-bbc4dcc32997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3, [1. 2. 3.], [[1. 2.]\n",
            " [4. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([1, 2, 3])"
      ],
      "metadata": {
        "id": "gmppLkjUv5vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Factory vs Constructor:\n",
        "# Factory is technically a constructor, but more high level. It does the initialziing to safe values.\n",
        "# Constructor is more manual. The user needs to initialize the things. Can be unsafe.\n",
        "# Try to use factory if possible.\n",
        "\n",
        "import torch\n",
        "\n",
        "t1 = torch.Tensor(numpy_array)\n",
        "# Constructor - same as torch.FloatTensor\n",
        "# uses a default float32 tensor, this bechanvor can be changed\n",
        "# all other tensors inherit from this main tensor class\n",
        "\n",
        "t2 = torch.tensor(numpy_array)\n",
        "# highly recommended to use!\n",
        "# Factory Function\n",
        "# call by value - creates a copy.\n",
        "# does not share underlying memory with numpy!\n",
        "# torch.tensor(data, dtype=None, device=None, requires_grad=False/True)\n",
        "\n",
        "\n",
        "t3 = torch.as_tensor(numpy_array)\n",
        "# recommended to use!\n",
        "# Factory Function\n",
        "# call by reference.\n",
        "# CAN ACCEPT ANY PYTHON DATA S3TRUCTURE INCLUDING NUMPY ARRAYS\n",
        "# always tries to avoid a copy of the data!\n",
        "# we have to manually call requires_grad() function on the final tensor. It does not support requires_grad by default\n",
        "\n",
        "\n",
        "t4 = torch.from_numpy(numpy_array)\n",
        "# Factory Function\n",
        "# produce a new tensor with the same data type\n",
        "# share the underlying memory with numpy, changing one, will change another!\n",
        "# CAN ACCEPT ONLY NUMPY ARRAYS"
      ],
      "metadata": {
        "id": "K8rLB16sv_Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array.dtype, t1.dtype, t2.dtype, t3.dtype, t4.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfi6GwUDxPjA",
        "outputId": "29f83700-a6ab-499a-a954-24c77bde055e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.float32, torch.int64, torch.int64, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array *= 4"
      ],
      "metadata": {
        "id": "G6Vi24xZyLqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAb2CvL9yu_3",
        "outputId": "c9c19a15-5692-4a93-867c-9e5fa6bdddfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4,  8, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1, t2, t3, t4 #[n, n, y, y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B42NH3JXywiC",
        "outputId": "1fab4ba7-1b1f-4196-940a-d90df0ab17e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3.]),\n",
              " tensor([1, 2, 3]),\n",
              " tensor([ 4,  8, 12]),\n",
              " tensor([ 4,  8, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 *= 2\n",
        "numpy_array, t1, t2, t3, t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pAagfpxy03E",
        "outputId": "e6dba551-749d-442b-a5d1-55408ad40c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 4,  8, 12]),\n",
              " tensor([2., 4., 6.]),\n",
              " tensor([1, 2, 3]),\n",
              " tensor([ 4,  8, 12]),\n",
              " tensor([ 4,  8, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 *= 2\n",
        "numpy_array, t1, t2, t3, t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi2a0Z45y--v",
        "outputId": "5895c2c1-3e3c-416e-8618-049ab8df7d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 4,  8, 12]),\n",
              " tensor([2., 4., 6.]),\n",
              " tensor([2, 4, 6]),\n",
              " tensor([ 4,  8, 12]),\n",
              " tensor([ 4,  8, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 *= 2\n",
        "numpy_array, t1, t2, t3, t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdA09sm6zB_a",
        "outputId": "8753480c-915c-438a-f701-b3e75278d2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 8, 16, 24]),\n",
              " tensor([2., 4., 6.]),\n",
              " tensor([2, 4, 6]),\n",
              " tensor([ 8, 16, 24]),\n",
              " tensor([ 8, 16, 24]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4 *= 2\n",
        "numpy_array, t1, t2, t3, t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulHeBSLnzFVa",
        "outputId": "63377196-5069-41da-c56c-6f5a90fff1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([16, 32, 48]),\n",
              " tensor([2., 4., 6.]),\n",
              " tensor([2, 4, 6]),\n",
              " tensor([16, 32, 48]),\n",
              " tensor([16, 32, 48]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 = t4.cuda()\n",
        "\n",
        "t5.device, t4.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohymfy6_zL6W",
        "outputId": "e0a1426b-b0a5-4523-e05a-1434052c1129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5 + t4 # Error because GPU + CPU won't work"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "gNbOIOnuzUKG",
        "outputId": "15f5d9d9-ca36-4aa4-e5e5-88998151cd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1786331611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt4\u001b[0m \u001b[0;31m# Error because GPU + CPU won't work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t4.device, t3.device)\n",
        "t6 = t4 + t3 # Works coz CPU+CPU\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIikp57XzYxy",
        "outputId": "bda9300e-48e4-4416-88ae-2325e4794c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 64, 96])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t6 = t4 + t5\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "k2Nd3HKUzeeU",
        "outputId": "2b708417-4cb7-4f33-c1e7-81352e1d40aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2838280936.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.eye(4, 4) # Returns an identity matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v151KtNmzhOB",
        "outputId": "2cbd0da2-f93f-49ae-ace5-b92221e5413e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqaLxi8Ozn0u",
        "outputId": "1dc8e51b-b6aa-4321-8231-bc68330c391c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agUpCld1z7zc",
        "outputId": "6b5a4c8c-5cb7-4c50-a1b3-9fa26d223838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6IGByFLz-O7",
        "outputId": "733deed7-736a-4757-ed0c-a4adb831b5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9072, 0.8401, 0.7497, 0.2120],\n",
              "        [0.3453, 0.1603, 0.8192, 0.6462],\n",
              "        [0.2440, 0.4739, 0.8784, 0.8103]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "data[1, 0], data[0, 0:2], data[:2, :2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpvuU3dk0HkM",
        "outputId": "26757c31-1669-433b-ce40-daab4dd5edaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4),\n",
              " tensor([1, 2]),\n",
              " tensor([[1, 2],\n",
              "         [4, 5]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Torch.tensor attributes\n",
        "\n",
        "| Attribute | Data Type | Description |\n",
        "|----|----|----|\n",
        "|data|array_like | list, tuple, NumPy ndarray, scalar |\n",
        "|dtype| torch.dtype | The tensor's data type|\n",
        "|requires_grad | bool| Should autograd record operation |\n",
        "|device | torch.device | Allocated on CPU or CUDA (GPU) |\n",
        "\n",
        "torch.tensor(data, dtype=None, device=None, requires_grad=False) â†’ Tensor\n"
      ],
      "metadata": {
        "id": "sepW4aIo02tt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[1][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqtpKPZb2Oie",
        "outputId": "ec317811-9b80-4a6a-a443-584251a598b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(data = [1, 2, 3], device='cuda', requires_grad=False)\n",
        "t.device, t.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAcw4b1vK6cN",
        "outputId": "ff135d63-0328-41bc-c8fc-62bd5963233f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cuda', index=0), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor(data = [1, 2, 3], dtype=torch.float32, device='cpu', requires_grad=False)\n",
        "t.device, t.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzrSTa4L2iFM",
        "outputId": "b12fca66-f169-4724-852d-dd694ae08f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(device(type='cpu'), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.as_tensor(data = [1, 2, 3], dtype=torch.float32, device='cpu', requires_grad=False)\n",
        "t\n",
        "\n",
        "# Error coz as_tensor is not designed to take the requires_grad and device parameters.\n",
        "# Because as_tensor does memory sharing and manipulating the grad and device in shared memory is not a good idea.\n",
        "# The is just a safety feature for not including these parameters."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vsNKX40L2uBu",
        "outputId": "5ff95b84-84f3-4634-91cd-be14f426dc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "as_tensor() got an unexpected keyword argument 'requires_grad'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2584364273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Error coz as_tensor is not designed to take the requires_grad and device parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Because as_tensor does memory sharing and manipulating the grad and device in shared memory is not a good idea.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: as_tensor() got an unexpected keyword argument 'requires_grad'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.as_tensor(data = [1, 2, 3], dtype=torch.float32, device='cpu')\n"
      ],
      "metadata": {
        "id": "sAu7CDNP2v6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.requires_grad_()\n",
        "\n",
        "# This works as it is not doing the grad at the time of creating as done previously"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs0vIB4m29G4",
        "outputId": "5c52510b-b37a-491c-f3d7-7b5656e6dc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd in PyTorch\n",
        "\n",
        "One of PyTorchâ€™s most powerful features is **Autograd**, its **automatic differentiation engine**.\n",
        "\n",
        "###  Key Ideas\n",
        "\n",
        "* **Automatic differentiation**: PyTorch tracks all tensor operations, so it can compute derivatives automatically.\n",
        "* **Dynamic graph**: The backward graph is built *on the fly* from the forward pass. This makes debugging, experimentation, and model changes very easy.\n",
        "* **Gradients**: Each tensor has an attribute `.grad` that stores the derivative of some scalar loss with respect to that tensor.\n",
        "* **Chain rule**: PyTorch applies the chain rule under the hood for backpropagation.\n",
        "\n",
        "---\n",
        "\n",
        "## Example: A Simple Gradient Computation\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Create a tensor with gradient tracking enabled\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Define a simple function: y = x^2 + 3x + 1\n",
        "y = x**2 + 3*x + 1\n",
        "\n",
        "# Backpropagate (compute dy/dx)\n",
        "y.backward()\n",
        "\n",
        "# Gradient is stored in x.grad\n",
        "print(f\"x: {x.item()}\")\n",
        "print(f\"y: {y.item()}\")\n",
        "print(f\"dy/dx: {x.grad.item()}\")\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "```\n",
        "x: 2.0\n",
        "y: 11.0\n",
        "dy/dx: 7.0\n",
        "```\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* $y = x^2 + 3x + 1$\n",
        "* Derivative: $dy/dx = 2x + 3$\n",
        "* At $x=2$, $dy/dx = 7$. PyTorch computed this automatically!\n",
        "\n",
        "---\n",
        "\n",
        "## Example: Working with Vectors\n",
        "\n",
        "```python\n",
        "# A vector of inputs\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "# A simple function: y = sum(x^2)\n",
        "y = (x**2).sum()\n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "print(\"x:\", x)\n",
        "print(\"Gradient dy/dx:\", x.grad)\n",
        "```\n",
        "\n",
        "Here, the gradient is simply $2x$, applied element-wise.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Autograd Matters\n",
        "\n",
        "* **Neural networks**: Training requires gradients of the loss w\\.r.t. millions of parameters â†’ Autograd handles this automatically.\n",
        "* **Flexibility**: Works with dynamic graphs, so models can have loops, conditionals, or variable architectures.\n",
        "* **Efficiency**: Optimized C++ backend with GPU acceleration.\n",
        "* **Integration**: Works seamlessly with `torch.optim` for gradient-based optimization.\n",
        "\n",
        "---\n",
        "\n",
        "**In short**: With Autograd, you just define your forward computation in PyTorch. The backward pass and gradients are taken care of automatically, enabling easy and fast experimentation with new models.\n",
        "\n"
      ],
      "metadata": {
        "id": "-4gQTEeg3Rrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad\n",
        "\n",
        "x1 = torch.tensor(2, requires_grad=True, dtype=torch.float16)\n",
        "x2 = torch.tensor(3, requires_grad=True, dtype=torch.float16)\n",
        "x3 = torch.tensor(1, requires_grad=True, dtype=torch.float16)\n",
        "x4 = torch.tensor(4, requires_grad=True, dtype=torch.float16)\n",
        "\n",
        "x1, x2, x3, x4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVRyhjS42-IM",
        "outputId": "315d6476-0ffc-4864-992f-fdf8e7350f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2., dtype=torch.float16, requires_grad=True),\n",
              " tensor(3., dtype=torch.float16, requires_grad=True),\n",
              " tensor(1., dtype=torch.float16, requires_grad=True),\n",
              " tensor(4., dtype=torch.float16, requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = x1 * x2\n",
        "z2 = x3 * x4\n",
        "\n",
        "print(f'z1 = {z1} and z2 = {z2}')\n",
        "f = z1 + z2\n",
        "print(f\"f = {f}\")\n",
        "\n",
        "# f = x1 * x2 + x3 * x4\n",
        "# f = 2 * 3 + 1 * 4\n",
        "# df_dx1 = 3\n",
        "# df_dx4 = 1\n",
        "\n",
        "df_dx = grad(outputs = f, inputs = [x1, x2, x3, x4])\n",
        "print(f'gradient of x1 = {df_dx[0]}')\n",
        "print(f'gradient of x2 = {df_dx[1]}')\n",
        "print(f'gradient of x3 = {df_dx[2]}')\n",
        "print(f'gradient of x4 = {df_dx[3]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HraoKkiF4UJm",
        "outputId": "83164df8-5ea4-493d-b275-3edaeaf0a727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z1 = 6.0 and z2 = 4.0\n",
            "f = 10.0\n",
            "gradient of x1 = 3.0\n",
            "gradient of x2 = 2.0\n",
            "gradient of x3 = 4.0\n",
            "gradient of x4 = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 input image, 2 correct predictions, then loss = 8\n",
        "10 input image, 4 correct predictions, then loss = 6\n",
        "10 input image, 5 correct predicitons, then loss = 5\n",
        "\n",
        "x1, x2, x3, x4 : 5, 6, 7, 8, then Loss = 5\n",
        "x1 changes from 5 to 5.5 (somehow).. then loss = 4 (we want that).. but we are not going to change 5 to 5.5, but rather 5 + LR*(0.5).. LR most probably is going to be 0.001"
      ],
      "metadata": {
        "id": "_7XTV-_y6XKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0-100000\n",
        "\n",
        "- iteration 1: Mutum 7... very very low\n",
        "- i2: mutum 9999... very low\n",
        "- i3: 99999.. very high\n",
        "- i4: 50000.. closer\n",
        "- i5: 55000.. very close\n",
        "- i6: 55600.. very very close\n",
        "- i7: 55650.. extremely close\n",
        "- i8: 55651.. ext ext close\n",
        "\n",
        "1000.. reduceLR_on_plateu\n"
      ],
      "metadata": {
        "id": "EMcoutTZ8Cib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad\n",
        "\n",
        "x1 = torch.tensor(2, requires_grad=True, dtype=torch.float16)\n",
        "x2 = torch.tensor(3, requires_grad=True, dtype=torch.float16)\n",
        "x3 = torch.tensor(1, requires_grad=True, dtype=torch.float16)\n",
        "x4 = torch.tensor(4, requires_grad=True, dtype=torch.float16)\n",
        "\n",
        "f = x1 * x2 + x3 * x4\n",
        "\n",
        "df_dx = grad(outputs = f, inputs = [x1, x2, x3, x4])\n",
        "print(f'gradient of x1 = {df_dx[0]}')\n",
        "print(f'gradient of x2 = {df_dx[1]}')\n",
        "print(f'gradient of x3 = {df_dx[2]}')\n",
        "print(f'gradient of x4 = {df_dx[3]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIqplUiI6zJl",
        "outputId": "256e90bc-817d-4b7d-f531-05cb67ed2897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient of x1 = 3.0\n",
            "gradient of x2 = 2.0\n",
            "gradient of x3 = 4.0\n",
            "gradient of x4 = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "opt = optim.SGD(params = [x1, x2, x3, x4], lr=0.001)\n",
        "opt.zero_grad()"
      ],
      "metadata": {
        "id": "OehRz5M09TsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import grad\n",
        "\n",
        "x1 = torch.tensor(2, requires_grad=True, dtype=torch.float16)\n",
        "x2 = torch.tensor(3, requires_grad=True, dtype=torch.float16)\n",
        "x3 = torch.tensor(1, requires_grad=True, dtype=torch.float16)\n",
        "x4 = torch.tensor(4, requires_grad=True, dtype=torch.float16)\n",
        "\n",
        "z1 = x1 * x2\n",
        "z2 = x3 * x4\n",
        "\n",
        "f = z1 + z2\n",
        "\n",
        "f.backward()\n",
        "\n",
        "print(f'gradient of x1 = {x1.grad}')\n",
        "print(f'gradient of x2 = {x2.grad}')\n",
        "print(f'gradient of x3 = {x3.grad}')\n",
        "print(f'gradient of x4 = {x4.grad}')\n",
        "\n"
      ],
      "metadata": {
        "id": "cWP-Z2D99uUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operation Types in PyTorch\n",
        "\n",
        "PyTorch tensors support a wide range of operations. These can be grouped into four broad categories:\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Reshaping Operations\n",
        "\n",
        "Reshaping operations change the **structure** of a tensor without altering the underlying data.\n",
        "\n",
        "* **`view()` / `reshape()`** â€“ Change shape\n",
        "* **`unsqueeze()` / `squeeze()`** â€“ Add or remove dimensions of size 1\n",
        "* **`transpose()` / `permute()`** â€“ Reorder dimensions\n",
        "* **`contiguous()`** â€“ Ensure memory continuity for reshaping\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.arange(6)              # [0, 1, 2, 3, 4, 5]\n",
        "x = x.view(2, 3)                 # Reshape to 2x3\n",
        "print(x)\n",
        "\n",
        "y = x.transpose(0, 1)            # Transpose (swap axes)\n",
        "print(y)\n",
        "\n",
        "z = x.unsqueeze(0)               # Add a new dimension at front\n",
        "print(z.shape)  # torch.Size([1, 2, 3])\n",
        "```\n",
        "\n",
        "âœ… **Use case:** Preparing tensors for batch processing, matrix multiplication, or feeding into neural network layers.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Element-wise Operations\n",
        "\n",
        "These apply functions **independently** to each element of the tensor.\n",
        "\n",
        "* Arithmetic: `+`, `-`, `*`, `/`, `**`\n",
        "* Comparison: `<`, `>`, `==`\n",
        "* Mathematical: `torch.exp`, `torch.log`, `torch.sin`, etc.\n",
        "\n",
        "```python\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([3.0, 2.0, 1.0])\n",
        "\n",
        "print(a + b)       # [4., 4., 4.]\n",
        "print(a * b)       # [3., 4., 3.]\n",
        "print(torch.exp(a))  # element-wise exponential\n",
        "```\n",
        "\n",
        "âœ… **Use case:** Activation functions, normalization, element-wise arithmetic in model layers.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Reduction Operations\n",
        "\n",
        "Reduction operations **aggregate tensor values** along one or more dimensions.\n",
        "\n",
        "* **`sum()`** â€“ Add elements\n",
        "* **`mean()`** â€“ Average values\n",
        "* **`max()` / `min()`** â€“ Get extreme values\n",
        "* **`argmax()` / `argmin()`** â€“ Index of max/min values\n",
        "* **`prod()`** â€“ Product of elements\n",
        "\n",
        "```python\n",
        "x = torch.tensor([[1., 2., 3.],\n",
        "                  [4., 5., 6.]])\n",
        "\n",
        "print(x.sum())             # 21\n",
        "print(x.mean(dim=0))       # [2.5, 3.5, 4.5]\n",
        "print(x.max(dim=1))        # values: [3., 6.], indices: [2, 2]\n",
        "```\n",
        "\n",
        "âœ… **Use case:** Loss functions, pooling in CNNs, summarizing predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Access Operations\n",
        "\n",
        "Access operations let you **retrieve or modify** specific elements or slices of a tensor.\n",
        "\n",
        "* **Indexing** (like Python lists): `x[0]`, `x[1, 2]`\n",
        "* **Slicing**: `x[:, 1:3]`\n",
        "* **Boolean indexing**: `x[x > 3]`\n",
        "* **Advanced indexing**: Gather elements by index tensors\n",
        "\n",
        "```python\n",
        "x = torch.tensor([[10, 20, 30],\n",
        "                  [40, 50, 60]])\n",
        "\n",
        "print(x[0, 1])        # 20\n",
        "print(x[:, 2])        # [30, 60]\n",
        "print(x[x > 30])      # [40, 50, 60]\n",
        "```\n",
        "\n",
        "âœ… **Use case:** Extracting minibatches, masking inputs, or modifying tensor values during preprocessing.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ”‘ Summary\n",
        "\n",
        "* **Reshaping** â†’ Change structure/dimensions (e.g., `.view()`, `.transpose()`)\n",
        "* **Element-wise** â†’ Operate on each element individually (e.g., `+`, `exp`)\n",
        "* **Reduction** â†’ Aggregate across dimensions (e.g., `sum`, `mean`, `max`)\n",
        "* **Access** â†’ Retrieve, slice, or mask values (e.g., indexing, boolean masks)\n",
        "\n"
      ],
      "metadata": {
        "id": "tGBk352498l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor([\n",
        "    [0, 0, 0, 0],\n",
        "    [1, 2, 3, 4],\n",
        "    [2, 2, 2, 2]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "zNM5Vkhx94MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape, t.size(), len(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF2QvQSpB1IG",
        "outputId": "8b156fd0-7b92-49cd-9a4b-1098e7a626d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 4]), torch.Size([3, 4]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(t.shape).prod()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npDWzRf_CCjN",
        "outputId": "baf1aabe-de64-4ea9-b25b-f0713166ee10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.numel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8eiLlc7COl1",
        "outputId": "7399161e-7c31-4749-bf85-93728a7811d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why knowing these is important?\n",
        "\n",
        "When we reshape a tensor, the reshaping operation must account for all of numel (or total number of elements). We if we have 12 elements, we can only build 1x12, 12x1, 6x2, 2x6, 3x4, 4x3 reshaped tensors"
      ],
      "metadata": {
        "id": "H5D_m-7hCTzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(1, 12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tqfkZ4sCR8_",
        "outputId": "58ddc62a-af8a-4084-861a-26bb380dd715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(2, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRBGfj0tCfsI",
        "outputId": "3c860fcb-339e-4bb2-8ca9-5969ddb22509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 1., 2.],\n",
              "        [3., 4., 2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(6, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MozBVC8jChzU",
        "outputId": "eb119379-dde7-44a5-dc83-7f76a61d3608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [1., 2.],\n",
              "        [3., 4.],\n",
              "        [2., 2.],\n",
              "        [2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(4, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WIBC5zrCo3z",
        "outputId": "099db688-2263-44df-ebd2-9c2c358cc898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 1., 2.],\n",
              "        [3., 4., 2.],\n",
              "        [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(2, 2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXUn6pQwCsFD",
        "outputId": "95e618c2-85fd-49df-a4d1-564a8b32232e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.],\n",
              "         [0., 1., 2.]],\n",
              "\n",
              "        [[3., 4., 2.],\n",
              "         [2., 2., 2.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1, 12))\n",
        "print(t.reshape(1, 12).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8WY5_UCuhU",
        "outputId": "674b0152-ce70-4238-945c-a91ab448e98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Squeezing a Tensor**\n",
        "\n",
        "Removes all the dimensions that have a length of 1\n",
        "\n",
        "**Unsqueezing a Tensor**\n",
        "Adds a dimension that has a length of 1."
      ],
      "metadata": {
        "id": "mR1hJ_ShC2RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1, 12))\n",
        "print(t.reshape(1, 12).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhGV-RebCxTJ",
        "outputId": "40d6a7e5-9b79-407a-aae6-92ffb156a717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1, 12).squeeze())\n",
        "print(t.reshape(1, 12).squeeze().shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgcUPthPFAFU",
        "outputId": "915e2c13-6a4a-4e7d-e3d6-4095c5746920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.])\n",
            "torch.Size([12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1, 12).squeeze().unsqueeze(dim = 0))\n",
        "print(t.reshape(1, 12).squeeze().unsqueeze(dim = 0).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJGGznT2FFXn",
        "outputId": "d400e2bf-0acf-41ae-e4de-a5d8c6472ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use cases?**\n",
        "\n",
        "Neural networks are always trained in a batch of samples. This is troubling because when we want to test 1 image, we do not have an array, we only have 1 image. Well we unsqueeze it to fake a batch.\n",
        "\n",
        "We use this function that is very common, called Flatten. This essentially create a new tensor that is only 1D. This is done to connect our data to next Fully Connected Layers. We use squeeze function for this.\n",
        "\n",
        "Let's implement such a function."
      ],
      "metadata": {
        "id": "pSm9IvR2FUeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vkctAwSFaEf",
        "outputId": "e7b8c6f2-17d8-4c5f-df13-7e1532319187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [1., 2., 3., 4.],\n",
              "        [2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatter(t):\n",
        "  t = t.reshape(1, -1)\n",
        "  t = t.squeeze()\n",
        "  return t\n",
        "\n",
        "t.shape, t\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhdugH_IFUF-",
        "outputId": "2ad335fc-528b-4eb2-b894-d6d3e080f651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 4]),\n",
              " tensor([[0., 0., 0., 0.],\n",
              "         [1., 2., 3., 4.],\n",
              "         [2., 2., 2., 2.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatter(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbzsBalXFSKy",
        "outputId": "70a985aa-0f87-439a-acdc-c12c44347def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 1., 2., 3., 4., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t1 = torch.tensor([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "])\n",
        "\n",
        "torch.cat((t1, t2), dim=0)\n",
        "\n",
        "# Vertical stacking --> dim = 0.\n",
        "# Horizonatal stacking --> dim = 1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffKTsGxDFjQZ",
        "outputId": "984c0ae6-449b-4e13-9250-dc7b5190de34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6],\n",
              "        [7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ops](https://ucarecdn.com/9f29f62d-5e96-430a-be4b-22f007983072/)"
      ],
      "metadata": {
        "id": "_-CjyRjbGEW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat((t1, t2), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfJG6bkAF-t5",
        "outputId": "3b910563-0ba3-4575-aa55-504def49ea6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 5, 6],\n",
              "        [3, 4, 7, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(2, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3wMe3_7GItD",
        "outputId": "d70dece2-4c46-4d00-eb37-546be6d48d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 1., 2.],\n",
              "        [3., 4., 2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = torch.tensor([\n",
        "  [1, 1, 1, 1],\n",
        "  [1, 1, 1, 1],\n",
        "  [1, 1, 1, 1],\n",
        "  [1, 1, 1, 1]\n",
        "])\n",
        "\n",
        "img2 = torch.tensor([\n",
        "  [2, 2, 2, 2],\n",
        "  [2, 2, 2, 2],\n",
        "  [2, 2, 2, 2],\n",
        "  [2, 2, 2, 2]\n",
        "])\n",
        "\n",
        "img3 = torch.tensor([\n",
        "  [3, 3, 3, 3],\n",
        "  [3, 3, 3, 3],\n",
        "  [3, 3, 3, 3],\n",
        "  [3, 3, 3, 3]\n",
        "])"
      ],
      "metadata": {
        "id": "ZmgnkE_tGK09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((img1, img2, img3))\n",
        "batch.shape, batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgCX5qvMGR7J",
        "outputId": "9d925cf5-03e7-4ab0-819e-8ba8bc055f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 4, 4]),\n",
              " tensor([[[1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1]],\n",
              " \n",
              "         [[2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2]],\n",
              " \n",
              "         [[3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Explanation of each dimension:\n",
        "## 3 â†’ batch size (3 images)\n",
        "## 1 â†’ number of channels (grayscale image)\n",
        "## 4 â†’ height\n",
        "## 4 â†’ width\n",
        "\n",
        "batch = batch.reshape(3, 1, 4, 4)\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm4KD9mvGT-w",
        "outputId": "f7896584-ac5d-4bae-84a1-26121a7845ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1]]],\n",
              "\n",
              "\n",
              "        [[[2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2]]],\n",
              "\n",
              "\n",
              "        [[[3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get our first image\n",
        "\n",
        "batch[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6z4dinVGj-o",
        "outputId": "1b39431a-625a-435f-d4c3-fe67df426620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get the first channel of our first image\n",
        "\n",
        "batch[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c0z7m0kGmbw",
        "outputId": "ff9fb10a-9f1a-4057-a80b-9d228188c3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get the first row of our first channel of our first image\n",
        "\n",
        "batch[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvHQihAhGpfC",
        "outputId": "e2f41e4b-2974-4926-f664-5d77140e993f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get the first pixel of the first row of our first channel of our first image\n",
        "\n",
        "batch[0][0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkXjhyRSGq6h",
        "outputId": "99db62d2-7570-450d-bac2-ce5d651ea037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how we flatten our image inside the batch\n",
        "\n",
        "batch.reshape(1, -1)[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBCJEyy5GsJR",
        "outputId": "f0a7695e-e3d2-4cc4-93af-f36c942f4f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.reshape(1, 4, -1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQg8E_91GvDB",
        "outputId": "2dfc2e88-a60a-4c61-a6b6-8fbc57a5d1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2],\n",
              "        [2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3],\n",
              "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.reshape(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9j6am_qGyld",
        "outputId": "b43fe914-e169-4c6c-e133-837658a4d51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xhaxMIdG0mP",
        "outputId": "681ad884-987d-4803-d040-278cd1021146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [5, 6],\n",
        "    [7, 8]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "d87NW3C2G3cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSAAqs1rIV3y",
        "outputId": "96d2607c-2ad5-4046-d738-9b21909c5c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.,  8.],\n",
              "        [10., 12.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IEaB4PcIZxX",
        "outputId": "afcb79dc-40ac-473c-8d90-91c00e879c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 - 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXlGw9-7Ib01",
        "outputId": "193ed60f-98b9-4eea-db2e-c77e729aa2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  0.],\n",
              "        [ 1.,  2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1.add(2))\n",
        "\n",
        "print(t1.sub(2))\n",
        "\n",
        "print(t1.mul(2))\n",
        "\n",
        "print(t1.div(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRA31Y_SId72",
        "outputId": "91d671ae-866e-411b-840b-9c710ea6dc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [0, 5, 7],\n",
        "    [6, 0, 7],\n",
        "    [0, 8, 0]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "XLf0v553IfXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.eq(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVE_wdVdIgrv",
        "outputId": "8479565a-0d4a-4afd-e6b8-c081246adf7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False, False],\n",
              "        [False,  True, False],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.ge(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JbS8XCAIizV",
        "outputId": "9af87358-1e18-4fd5-e715-fa75e2afaf28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.le(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V4WusCjIj0h",
        "outputId": "1cbe95fc-ee73-461a-d32d-a341504b4fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.abs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T61Tu6GLImEH",
        "outputId": "50414553-d9e8-4ba1-a38d-bd7c7c6f67b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 5., 7.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.sqrt()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSYsXjDvInLt",
        "outputId": "0d06aed6-38dc-4750-8bec-6b601240853d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 2.2361, 2.6458],\n",
              "        [2.4495, 0.0000, 2.6458],\n",
              "        [0.0000, 2.8284, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [0, 5, 7],\n",
        "    [6, 0, 7],\n",
        "    [0, 8, 0]\n",
        "], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "tTcHK3pmIo-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXnIAeRdIqPG",
        "outputId": "f47bf0e1-fdca-43b1-bee2-c9fa097888be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(33.)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.prod()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQxIM1BKIrCu",
        "outputId": "fe5b561d-6499-4e04-b89e-1bcba71eadef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92ppDTDIsBT",
        "outputId": "169aad6b-5f1e-4e3d-e872-d7b414113e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.6667)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ6X1nywItWJ",
        "outputId": "aadec9fd-99c1-4f57-9884-da8326456d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.5707)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "  [1, 1, 1, 1],\n",
        "  [2, 2, 2, 2],\n",
        "  [3, 3, 3, 3],\n",
        "  [4, 4, 4, 4]\n",
        "])"
      ],
      "metadata": {
        "id": "nsIGsjW8IuSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum(dim=0) # Vertical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGL3bpyAIvMN",
        "outputId": "8f61a3ce-b481-4f9e-c4d6-742c6c593978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 10, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum(dim=1) # Horizontal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SftqXkDEIzAP",
        "outputId": "0316a583-92f7-4183-daff-625e4f9988a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4,  8, 12, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.argmax(), t.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiCyiZSaI1vQ",
        "outputId": "3c3da909-7079-4d00-b6d9-628a72325ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(12), tensor(4))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "  [1, 1, 1, 1],\n",
        "  [2, 2, 2, 2],\n",
        "  [3, 3, 3, 3],\n",
        "  [4, 4, 5, 4]\n",
        "])\n",
        "t.argmax(), t.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1hVoYoJI3tH",
        "outputId": "daa96a9a-d362-4928-bf59-9afc5d5dcc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(14), tensor(5))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.argmin(), t.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBoSqqc2I8N5",
        "outputId": "d7bc2a2a-2171-42c3-c512-636722700a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWbMcmH-I_JV",
        "outputId": "89d9d68f-e7ff-4f71-8270-7c116c9b9abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is `contiguous()`?\n",
        "\n",
        "* A **tensor is contiguous** if its memory layout is stored sequentially (row-major order by default).\n",
        "* Some operations (e.g., `transpose`, `permute`) only **change the view** of a tensor without actually rearranging memory.\n",
        "* If you then try to call `.view()` on a non-contiguous tensor, PyTorch will complain.\n",
        "* `.contiguous()` **forces a copy** of the tensor into contiguous memory.\n",
        "\n",
        "---\n",
        "\n",
        "## Example: Memory Layout Proof\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "# Step 1: Create a 2x3 tensor\n",
        "x = torch.arange(6).view(2, 3)\n",
        "print(\"Original tensor:\\n\", x)\n",
        "\n",
        "# Step 2: Transpose (non-contiguous!)\n",
        "y = x.t()\n",
        "print(\"\\nTransposed tensor:\\n\", y)\n",
        "\n",
        "# Check if contiguous\n",
        "print(\"\\nIs y contiguous?\", y.is_contiguous())\n",
        "\n",
        "# Step 3: Try to use view() on non-contiguous tensor\n",
        "try:\n",
        "    y.view(6)\n",
        "except RuntimeError as e:\n",
        "    print(\"\\nError:\", e)\n",
        "\n",
        "# Step 4: Make it contiguous\n",
        "z = y.contiguous()\n",
        "print(\"\\nContiguous tensor:\\n\", z)\n",
        "print(\"Is z contiguous?\", z.is_contiguous())\n",
        "\n",
        "# Step 5: Show memory addresses\n",
        "print(\"\\nMemory addresses:\")\n",
        "print(\"y.storage():\", y.storage())\n",
        "print(\"z.storage():\", z.storage())\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Sample Output\n",
        "\n",
        "```\n",
        "Original tensor:\n",
        " tensor([[0, 1, 2],\n",
        "         [3, 4, 5]])\n",
        "\n",
        "Transposed tensor:\n",
        " tensor([[0, 3],\n",
        "         [1, 4],\n",
        "         [2, 5]])\n",
        "\n",
        "Is y contiguous? False\n",
        "\n",
        "Error: view size is not compatible with input tensor's size and stride\n",
        "\n",
        "Contiguous tensor:\n",
        " tensor([[0, 3],\n",
        "         [1, 4],\n",
        "         [2, 5]])\n",
        "Is z contiguous? True\n",
        "\n",
        "Memory addresses:\n",
        "y.storage():  0 1 2 3 4 5   (non-linear stride mapping)\n",
        "z.storage():  0 3 1 4 2 5   (copied into sequential memory)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Why is it used?\n",
        "\n",
        "1. **Reshaping with `.view()`**\n",
        "\n",
        "   * `.view()` requires a tensor to be contiguous because it assumes linear memory.\n",
        "   * `.contiguous()` fixes this by rearranging data in memory.\n",
        "\n",
        "2. **Performance**\n",
        "\n",
        "   * Some operations (like matrix multiplications) are optimized for contiguous memory.\n",
        "   * Non-contiguous layouts can cause slower performance.\n",
        "\n",
        "3. **Correctness**\n",
        "\n",
        "   * After transpose/permute, data strides are different. `.contiguous()` ensures safe reshaping and consistent memory access.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”‘ Rule of Thumb\n",
        "\n",
        "* Use `.contiguous()` **only when necessary** (e.g., before `.view()` or when operations explicitly require contiguous memory).\n",
        "* Donâ€™t call it unnecessarily, since it forces a memory copy.\n",
        "\n"
      ],
      "metadata": {
        "id": "rJVmjvsbJCfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(6).view(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131IsRZKJLbe",
        "outputId": "be24188d-52aa-4224-fbe9-a3e6da64c8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [3, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a 2x3 tensor\n",
        "x = torch.arange(6).view(2, 3)\n",
        "print(\"Original tensor:\\n\", x)\n",
        "\n",
        "# Step 2: Transpose (non-contiguous!)\n",
        "y = x.t()\n",
        "print(\"\\nTransposed tensor:\\n\", y)\n",
        "\n",
        "# Check if contiguous\n",
        "print(\"\\nIs y contiguous?\", y.is_contiguous())\n",
        "\n",
        "# Step 3: Try to use view() on non-contiguous tensor\n",
        "try:\n",
        "    y.view(6)\n",
        "except RuntimeError as e:\n",
        "    print(\"\\nError:\", e)\n",
        "\n",
        "# Step 4: Make it contiguous\n",
        "z = y.contiguous()\n",
        "print(\"\\nContiguous tensor:\\n\", z)\n",
        "print(\"Is z contiguous?\", z.is_contiguous())\n",
        "\n",
        "# Step 5: Show memory addresses\n",
        "print(\"\\nMemory addresses:\")\n",
        "print(\"x.storage():\", x.storage())\n",
        "print(\"y.storage():\", y.storage())\n",
        "print(\"z.storage():\", z.storage())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Btn2fFgJCJA",
        "outputId": "f93b434a-c081-4724-c3a9-3477697b45e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "\n",
            "Transposed tensor:\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "\n",
            "Is y contiguous? False\n",
            "\n",
            "Error: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
            "\n",
            "Contiguous tensor:\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n",
            "Is z contiguous? True\n",
            "\n",
            "Memory addresses:\n",
            "x.storage():  0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
            "y.storage():  0\n",
            " 1\n",
            " 2\n",
            " 3\n",
            " 4\n",
            " 5\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n",
            "z.storage():  0\n",
            " 3\n",
            " 1\n",
            " 4\n",
            " 2\n",
            " 5\n",
            "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# PyTorch Main\n",
        "\n",
        "# Working with the dataset\n",
        "\n",
        "We will look at convolutional/image examples as they allow us to get a good intuition on axises and are more complex to work on just 1D data\n",
        "\n",
        "### A common nn pipeline looks like this:\n",
        "1. Prepare the data\n",
        "2. Build the model\n",
        "3. Train the model\n",
        "4. Analyze the model"
      ],
      "metadata": {
        "id": "wLhdiHnDJcfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "iQWkQbg9JA6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Animals(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    r = self.data.iloc[index]\n",
        "    label, image = r\n",
        "    return label, image\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "PLu8qH_FJjVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's work with FashionMnist\n",
        "\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root='./data'\n",
        "    ,train=True\n",
        "    ,download=True\n",
        "    ,transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "28iAgqA6J1SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in range(10):\n",
        "  print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPyZ3q2tJ999",
        "outputId": "aada2fef-13b8-4e97-b259-b5b0d72fc30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = iter(range(10))\n",
        "x, next(x), next(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y_eqyezKIZd",
        "outputId": "5a086525-4359-4553-d3bb-83dfa625deff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<range_iterator at 0x79f431459a40>, 0, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = iter(range(10))\n",
        "next(x), next(x), next(x), next(x), next(x), next(x), next(x), next(x), next(x), next(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S51vURnJ5PT",
        "outputId": "cb1a6c38-b061-455c-a3d4-42628e13d2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MxX_RLrKWqp",
        "outputId": "7c862458-d888-44a7-9ca7-8015c5f2a1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_set))[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9N3ZQcoKfGF",
        "outputId": "a0c5b508-3c9b-4411-de05-916b17db066f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(range(10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHEbySlhKiWx",
        "outputId": "0975c008-8733-4a4f-dcd2-e24520ddd600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "\n",
        "for j in train_set:\n",
        "  print(j[1])\n",
        "  i+= 1\n",
        "  if i > 5:\n",
        "    break"
      ],
      "metadata": {
        "id": "H13TLBPJKv8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set\n",
        "    ,batch_size=32\n",
        "    ,shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "pAN4EBK7K2S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter(train_loader)"
      ],
      "metadata": {
        "id": "sDZIemNmK-XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[1]"
      ],
      "metadata": {
        "id": "2ju2Em1fLCXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(linewidth=120)"
      ],
      "metadata": {
        "id": "HJ7Rr0HnLEfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_set)"
      ],
      "metadata": {
        "id": "ASYkA9huMHIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.train_labels"
      ],
      "metadata": {
        "id": "rhQc1K1pMIfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.train_labels.bincount() #frequency of each label, we have balanced class here"
      ],
      "metadata": {
        "id": "wVyiJBGOMJpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_set))\n",
        "\n",
        "len(sample)"
      ],
      "metadata": {
        "id": "GQebKw_RMMCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = sample"
      ],
      "metadata": {
        "id": "7R6yKP69MPkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('label:', label)"
      ],
      "metadata": {
        "id": "rnrWrGSaMRHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "\n",
        "len(batch), type(batch)"
      ],
      "metadata": {
        "id": "cCOHVH4jMTUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = batch"
      ],
      "metadata": {
        "id": "nqgm4sYQMWvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape, labels.shape"
      ],
      "metadata": {
        "id": "FA9E7OVTMY7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = torchvision.utils.make_grid(images, nrow=10)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "print('labels:', labels)"
      ],
      "metadata": {
        "id": "07ko8qVsMaBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer = None\n",
        "\n",
        "  def forward(self, t):\n",
        "    t = self.layer(t)\n",
        "    return t\n"
      ],
      "metadata": {
        "id": "MmowwoArMeJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Main (Let's start again)\n",
        "\n",
        "# Working with the dataset\n",
        "\n",
        "We will look at convolutional/image examples as they allow us to get a good intuition on axises and are more complex to work on just 1D data\n",
        "\n",
        "### A common nn pipeline looks like this:\n",
        "1. Prepare the data\n",
        "2. Build the model\n",
        "3. Train the model\n",
        "4. Analyze the model"
      ],
      "metadata": {
        "id": "UCxPe_JjNIHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "EVZoqKFkNETn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Dataset is there to be able to interact with DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = (\n",
        "        \"This was an amazing product\",\n",
        "        \"This was the shittiest product possible\",\n",
        "        \"Amazing product, fast delivery\",\n",
        "        \"Had to sell my kidney to buy this, and now my life has changed\",\n",
        "        \"Good one!\",\n",
        "        \"Bad One!\"\n",
        "    )\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print(m)\n",
        "\n"
      ],
      "metadata": {
        "id": "sMNSXCQZNMFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(myData, batch_size = 2, shuffle=True)"
      ],
      "metadata": {
        "id": "sojZi2qiNL0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tr in train_loader:\n",
        "  print(tr)"
      ],
      "metadata": {
        "id": "A8XMyaQ2Nf8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "h1If-lviNgUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in train_set:\n",
        "  print(f)\n",
        "  break"
      ],
      "metadata": {
        "id": "uRIEVNfpN3LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.set_printoptions(linewidth=120)\n",
        "\n",
        "len(train_set)"
      ],
      "metadata": {
        "id": "2CyIZYHXN5DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(train_set)"
      ],
      "metadata": {
        "id": "M79u8aG-N8g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.train_labels.bincount()"
      ],
      "metadata": {
        "id": "y-POMECMN-OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_set))\n",
        "sample"
      ],
      "metadata": {
        "id": "F8BU1wMhOAcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = sample\n",
        "image.size()"
      ],
      "metadata": {
        "id": "D1g7s9AYOBW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "print('label:', label)"
      ],
      "metadata": {
        "id": "XDbF61ymODvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size = 32,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "dcj8hu74OGa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tl in train_loader:\n",
        "  print(len(tl[0]))\n",
        "  print(tl[1])\n",
        "  break"
      ],
      "metadata": {
        "id": "VyoyVOiKOIqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ],
      "metadata": {
        "id": "32MMAMsqOJxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = batch\n",
        "\n",
        "images.shape, labels.shape"
      ],
      "metadata": {
        "id": "3szn2gWkOMMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = torchvision.utils.make_grid(images, nrow=10)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "print('labels:', labels)"
      ],
      "metadata": {
        "id": "wUNDU2N9OOSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer = None\n",
        "\n",
        "  def forward(self, t):\n",
        "    t = self.layer(t)\n",
        "    return t"
      ],
      "metadata": {
        "id": "R2T7Un74OPH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "# 9x9 convolved by 3x3> 7x7... 7x7 by 3x3.. 5x5\n",
        "# 9x9 convolved by 5x5 > 5x5\n",
        "\n",
        "    # input 28 # output 24 # receptive_field = 5\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    # input 24 # output 20 # receptive_field = 9\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    # output > 20x20x12\n",
        "    # input 12x20x20, output 120\n",
        "    # input 10*512\n",
        "    self.fc1 = nn.Linear(in_features=12*20*20, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  def forward(self, t): # empty\n",
        "    return t\n"
      ],
      "metadata": {
        "id": "1FL_KFixORMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "\n",
        "print(network)"
      ],
      "metadata": {
        "id": "yX9oQhXfPqZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.fc2"
      ],
      "metadata": {
        "id": "B1btb9joQ8KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(network.fc2)"
      ],
      "metadata": {
        "id": "9cKT4NqoQ-V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.fc2.weight"
      ],
      "metadata": {
        "id": "sQsXW2cXRCSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.fc2.weight.shape"
      ],
      "metadata": {
        "id": "PpYGQUTTRFjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=12*20*20, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  def forward(self, t):\n",
        "    # TODO implement this\n",
        "    return t\n",
        "\n",
        "network = Network()\n",
        "\n",
        "for name, param in network.named_parameters():\n",
        "  print(name, '\\t\\t', param.shape)"
      ],
      "metadata": {
        "id": "_oOYfwm2RHJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "6vyGLyDORN6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10) # 600 parameters of size 60x10. Input 60 inputs.\n",
        "\n",
        "  def forward(self, t):\n",
        "    # input layer\n",
        "    x = t\n",
        "    # conv1 layer\n",
        "    x = self.conv1(x) # 1x28x28 > 6x24x24\n",
        "    x = F.relu(x) # 6x24x24 > 6x24x24\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 6x24x24 > 6x12x12\n",
        "    # conv2 layer\n",
        "    x = self.conv2(x) # 6x12x12 > 12x8x8\n",
        "    x = F.relu(x) # no change\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) #  12x8x8 > 12x4x4\n",
        "    # reshapre\n",
        "    x = x.reshape(-1, 12 * 4 * 4)\n",
        "    # fc1 layer\n",
        "    x = self.fc1(x) # 192 > 120\n",
        "    x = F.relu(x)\n",
        "    # fc2 layer\n",
        "    x = self.fc2(x) # 120 > 10\n",
        "    x = F.relu(x)\n",
        "    # output layer\n",
        "    x = self.out(x)\n",
        "    # x = F.softmax(x, dim=1)\n",
        "    return x"
      ],
      "metadata": {
        "id": "wBKqmQRrRR59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)"
      ],
      "metadata": {
        "id": "QLAdBtpDTyHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_set))\n",
        "image, label = sample\n",
        "image.shape, image.unsqueeze(0).shape\n"
      ],
      "metadata": {
        "id": "wYgfYxPDT0UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()"
      ],
      "metadata": {
        "id": "GHbxThdDT4Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = network(image) # this is modern PyTorch"
      ],
      "metadata": {
        "id": "Bp2gSvLWT5J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = network(image.unsqueeze(0))  # this is old PyTorch"
      ],
      "metadata": {
        "id": "AM-NubwGT6nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred, label # [0,0,0,0,0,0,0,0,0,1]"
      ],
      "metadata": {
        "id": "mtNoozIoUFSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred, pred.shape, label"
      ],
      "metadata": {
        "id": "sSTlnTSqULUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.argmax(dim=1) # this time its 6 and 9"
      ],
      "metadata": {
        "id": "4iOxg9I7Ucl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(pred, dim=1)"
      ],
      "metadata": {
        "id": "UGzzFpjrUfxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOFTMAX"
      ],
      "metadata": {
        "id": "buCmiVDOWP4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input values\n",
        "x = torch.tensor([4., 3., 2., 1.])\n",
        "\n",
        "# Apply softmax\n",
        "softmax_vals = F.softmax(x, dim=0)\n",
        "\n",
        "# Labels rounded for display\n",
        "labels = [f\"{val.item():.2f}\" for val in x]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "# Original values\n",
        "plt.bar([i-0.2 for i in range(len(x))], x, width=0.4, label=\"Original values\", alpha=0.7)\n",
        "\n",
        "# Softmax probabilities\n",
        "plt.bar([i+0.2 for i in range(len(x))], softmax_vals, width=0.4, label=\"Softmax probabilities\", alpha=0.7)\n",
        "\n",
        "# Fix x-axis ticks\n",
        "plt.xticks(range(len(x)), labels)\n",
        "plt.ylabel(\"Value / Probability\")\n",
        "plt.title(\"Softmax: Exponential Effect on Input Values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-8XbcBgkUjyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input values\n",
        "x = torch.tensor([0.4, 0.3, 0.2, 0.1])\n",
        "\n",
        "# Apply softmax\n",
        "softmax_vals = F.softmax(x, dim=0)\n",
        "\n",
        "# Labels rounded for display\n",
        "labels = [f\"{val.item():.2f}\" for val in x]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "# Original values\n",
        "plt.bar([i-0.2 for i in range(len(x))], x, width=0.4, label=\"Original values\", alpha=0.7)\n",
        "\n",
        "# Softmax probabilities\n",
        "plt.bar([i+0.2 for i in range(len(x))], softmax_vals, width=0.4, label=\"Softmax probabilities\", alpha=0.7)\n",
        "\n",
        "# Fix x-axis ticks\n",
        "plt.xticks(range(len(x)), labels)\n",
        "plt.ylabel(\"Value / Probability\")\n",
        "plt.title(\"Softmax: Exponential Effect on Input Values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ftqy6iDmWQ6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(pred, dim=1).sum()"
      ],
      "metadata": {
        "id": "TgzzZ8xVWZma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=10\n",
        ")"
      ],
      "metadata": {
        "id": "cpEFJS9AW5Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(data_loader))\n",
        "len(batch[0])"
      ],
      "metadata": {
        "id": "L0e98yOiW7m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = batch\n",
        "\n",
        "preds = network(images)\n",
        "preds.shape"
      ],
      "metadata": {
        "id": "ohvSSCHvW9AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "kBrIrJCJW-Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(dim=1)"
      ],
      "metadata": {
        "id": "5XfD48gLXIbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "QJRXaquwXm63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds.argmax(dim=1).eq(labels)"
      ],
      "metadata": {
        "id": "mEUq5lc7XLP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "UHLnOO3tXPkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "961k3q-LXThQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ],
      "metadata": {
        "id": "Ep-1SirJXUuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels) # [0.1, 0.2, 0.4] - [0, 0, 1] | (0-0.1)**2 + (0-0.2)**2 + (1-0.4)**2 = LOSS????\n",
        "loss.item()"
      ],
      "metadata": {
        "id": "wxUt9MgBXrd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Natural logarithm (base e)\n",
        "log_e = math.log(1/10)\n",
        "\n",
        "print(\"ln(1/10):\", log_e)\n"
      ],
      "metadata": {
        "id": "DM7yR61NYE4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(network.conv1.weight.grad)"
      ],
      "metadata": {
        "id": "puRLJ423YSlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "g7X8u-NjZ4HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(network.conv1.weight.grad)"
      ],
      "metadata": {
        "id": "pCtw8yAhZ9LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3x3 = network.conv1.weight[1, 0].detach().cpu()\n",
        "kernel_3x3"
      ],
      "metadata": {
        "id": "C7fi8RsEZ_Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3x3_grad = network.conv1.weight.grad[1, 0].detach().cpu()\n",
        "kernel_3x3_grad"
      ],
      "metadata": {
        "id": "5yZutDLNaJf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(network.conv1.weight.grad.shape)"
      ],
      "metadata": {
        "id": "h9FDQcpjb819"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(network.parameters(), lr = 0.01)"
      ],
      "metadata": {
        "id": "V5gqTVxqcBDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "x3RgNtHycKs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_3x3 = network.conv1.weight[1, 0].detach().cpu()\n",
        "kernel_3x3"
      ],
      "metadata": {
        "id": "q68vvGTtcFFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "KcD_xsqScIIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "SYohkBXJc5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "StJeWg16c-nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "fgZ9yjUMdAAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "JFxKfHBbdB-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "ESA7hBsRdDPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "BA40xCUbdEFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "U1QWUmzAdFNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "optimizer.zero_grad()\n",
        "optimizer.step()\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "loss.item(), get_num_correct(preds, labels)"
      ],
      "metadata": {
        "id": "pxBIKZ3VdGRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
        "\n",
        "batch = next(iter(train_loader)) # Get Batch\n",
        "images, labels = batch\n",
        "\n",
        "preds = network(images) # Pass Batch\n",
        "loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "\n",
        "loss.backward() # Calculate Gradients\n",
        "optimizer.step() # Update Weights\n",
        "\n",
        "print('loss1:', loss.item())\n",
        "preds = network(images)\n",
        "loss = F.cross_entropy(preds, labels)\n",
        "print('loss2:', loss.item())"
      ],
      "metadata": {
        "id": "JH2g8KkadH5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)\n",
        "torch.set_grad_enabled(True)"
      ],
      "metadata": {
        "id": "BTvtlPqTdQqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "optimizer = optim.Adam(network.parameters(), lr=1e-3)  # 0.01 is high for Adam\n",
        "\n",
        "network.train()\n",
        "\n",
        "total_loss = 0.0          # will store SUM of per-example losses\n",
        "total_correct = 0\n",
        "total_examples = 0\n",
        "\n",
        "for batch in train_loader:  # Get Batch\n",
        "    images, labels = batch\n",
        "    # labels should be class indices (LongTensor)\n",
        "    if labels.dtype != torch.long:\n",
        "        labels = labels.long()\n",
        "\n",
        "    preds = network(images)                       # Pass Batch (logits)\n",
        "    loss = F.cross_entropy(preds, labels)         # mean loss over this batch\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()                               # Calculate Gradients\n",
        "    optimizer.step()                               # Update Weights\n",
        "\n",
        "    bs = images.size(0)\n",
        "    total_loss += loss.item() * bs                # accumulate per-example loss\n",
        "    total_correct += get_num_correct(preds, labels)\n",
        "    total_examples += bs\n",
        "\n",
        "avg_loss = total_loss / total_examples\n",
        "print(\n",
        "    \"epoch:\", 0,\n",
        "    \"total_correct:\", total_correct,\n",
        "    \"accuracy:\", f\"{total_correct/total_examples:.4%}\",\n",
        "    \"loss:\", f\"{avg_loss:.4f}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "bgf_Uu6TdXiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- loss.backward>> calculate gradients and store in weights(100)\n",
        "- loss.backward>> add new gradients to old ones (200)\n",
        "100\n",
        "- optim.step>> updates the weights"
      ],
      "metadata": {
        "id": "td-IYHA3dpqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "# 1. Pick device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 2. Build and move model to device\n",
        "network = Network().to(device)\n",
        "\n",
        "# 3. Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
        "\n",
        "# 4. Optimizer\n",
        "optimizer = optim.Adam(network.parameters(), lr=1e-3)\n",
        "\n",
        "# 5. Helper\n",
        "def get_num_correct(logits, labels):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    return (preds == labels).sum().item()\n",
        "\n",
        "# 6. Training loop\n",
        "for epoch in range(10):\n",
        "    network.train()\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # move batch to GPU\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        if labels.dtype != torch.long:\n",
        "            labels = labels.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = network(images)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        batch_size = images.size(0)\n",
        "        running_loss += loss.item() * batch_size\n",
        "        running_correct += get_num_correct(logits, labels)\n",
        "        total_examples += batch_size\n",
        "\n",
        "    epoch_loss = running_loss / total_examples\n",
        "    epoch_acc = running_correct / total_examples\n",
        "\n",
        "    print(f\"epoch {epoch:02d}  loss: {epoch_loss:.4f}  acc: {epoch_acc:.4%}\")\n"
      ],
      "metadata": {
        "id": "p5O9yHHJeYwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyBUMiOTFthisWasRohansKeyWhichIsNotThereAgkW8IfpT33o\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\", contents=\"Explain why nearly everyone has moved out from Tensorflow to PyTorch?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "otCWwC2CiwQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While \"nearly everyone has moved out from TensorFlow to PyTorch\" might be an exaggeration, there's a strong and undeniable trend, especially in **academia, research, and new projects**, towards PyTorch. Many companies and existing large-scale deployments still heavily rely on TensorFlow.\n",
        "\n",
        "However, the reasons for this significant shift are compelling and center around **developer experience, flexibility, and ease of use.**\n",
        "\n",
        "Here's a breakdown of why PyTorch gained so much traction:\n",
        "\n",
        "1.  **Dynamic Computation Graphs (\"Define by Run\")**\n",
        "    *   **The Problem with TensorFlow 1.x:** TensorFlow 1.x used a **static computation graph** (\"Define and Run\"). You first had to build the entire graph of operations (like a blueprint) and *then* feed data into it to execute. This was great for optimization and deployment, but:\n",
        "        *   **Debugging was a nightmare:** If something went wrong, you'd get cryptic errors often unrelated to the line of code that caused the issue, as the error came from the graph execution, not the graph definition.\n",
        "        *   **Limited flexibility:** Control flow (if/else statements, loops) was difficult to implement dynamically within the graph. This made it challenging for models with variable structures (like RNNs with variable sequence lengths) or advanced techniques like reinforcement learning.\n",
        "        *   **Less intuitive:** It felt less like writing regular Python code.\n",
        "    *   **PyTorch's Solution:** PyTorch adopted a **dynamic computation graph** (\"Define by Run\"). Operations are executed immediately as they are defined, just like regular Python code.\n",
        "        *   **Easy Debugging:** You can use standard Python debuggers (pdb, IDE debuggers) and inspect tensors at any point. Errors are precise and point to the exact line of code.\n",
        "        *   **Pythonic Control Flow:** You can use native Python if/else statements and loops directly, making it incredibly flexible for complex models.\n",
        "        *   **More Intuitive:** It feels much more like writing standard Python code, making it easier for new users to pick up.\n",
        "\n",
        "2.  **Developer Experience and Pythonic API**\n",
        "    *   **Less Boilerplate:** PyTorch generally requires less boilerplate code to define models and training loops.\n",
        "    *   **NumPy-like Interface:** PyTorch's tensor operations are very similar to NumPy arrays, making it familiar and easy for Python data scientists to transition.\n",
        "    *   **Simplicity:** The API is often perceived as cleaner and more straightforward.\n",
        "\n",
        "3.  **Community and Ecosystem**\n",
        "    *   **Research Adoption:** PyTorch quickly became the de-facto standard in academia and research due to its flexibility and ease of rapid prototyping. This led to a massive influx of research papers, open-source projects, and pre-trained models being released in PyTorch.\n",
        "    *   **Active Community:** A vibrant and active community provides extensive support, tutorials, and shared resources.\n",
        "\n",
        "4.  **Learning Curve**\n",
        "    *   For many, especially those coming from a pure Python background, PyTorch has a significantly gentler learning curve compared to the complexities of TensorFlow 1.x's graph construction.\n",
        "\n",
        "**TensorFlow 2.x's Response â€“ Too Little, Too Late for Some?**\n",
        "\n",
        "Google recognized these issues and completely overhauled TensorFlow with **TensorFlow 2.x**. Key changes included:\n",
        "*   **Eager Execution (Dynamic Graphs) by default:** TF 2.x adopted dynamic graphs, essentially bringing the \"Define by Run\" paradigm that PyTorch popularized.\n",
        "*   **Keras Integration:** Keras became the high-level API for TensorFlow, significantly simplifying model building.\n",
        "*   **Cleaner API:** Efforts were made to simplify and unify the API.\n",
        "\n",
        "While TF 2.x is a massive improvement and closed many of the gaps with PyTorch, the momentum had already shifted significantly. Many developers, researchers, and startups had already invested heavily in PyTorch, built their systems around it, and were comfortable with its established ecosystem. Changing frameworks, even to an improved version of the original, can be a non-trivial decision.\n",
        "\n",
        "**Where TensorFlow Still Shines (and isn't \"everyone\" abandoning it):**\n",
        "\n",
        "Despite the trend, TensorFlow remains incredibly powerful and is still widely used, especially in certain contexts:\n",
        "\n",
        "*   **Production Deployment:** TensorFlow has a more mature and robust ecosystem for production deployment (e.g., TensorFlow Serving, TensorFlow Lite for mobile/edge devices, TensorFlow Extended (TFX) for full MLOps pipelines).\n",
        "*   **Scalability (Historically):** TensorFlow was built from the ground up for Google's massive-scale distributed computing, and while PyTorch has caught up significantly, TF still benefits from that legacy for certain types of enterprise-scale deployments.\n",
        "*   **TPU Support:** For companies leveraging Google's Tensor Processing Units (TPUs), TensorFlow often has tighter integration and optimization.\n",
        "*   **Existing Investments:** Many large companies have significant legacy investments in TensorFlow 1.x or 2.x and established MLOps pipelines built around it. Migrating these systems is a massive undertaking.\n",
        "\n",
        "In summary, the move towards PyTorch is driven by its superior **developer experience, flexibility, and ease of use, particularly in research and rapid prototyping.** While TensorFlow 2.x addressed many of these criticisms, PyTorch had already captured the hearts and minds of a large segment of the ML community."
      ],
      "metadata": {
        "id": "YUz-zDsdjkp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Explain how AI works in a a lot of words\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=1) # Disables thinking\n",
        "    ),\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "qGPMKYpGjON-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give me the list of top 20 countries, their GDP, population, capital names, major exports only in JSON form. DO NOT add any other text."
      ],
      "metadata": {
        "id": "uKs34sMFkhTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\", contents=\"Give me the list of top 20 countries, their GDP, population, capital names, major exports only in JSON form. DO NOT add any other text. \"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "HRkqc_yEjxEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9jSpXXXk18s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}